{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run last_task_preprocessing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cluster_counter\n",
    "y = df.drop('cluster_counter', axis=1).to_numpy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "           random_state=1,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50), (50,100,50)],\n",
    "    'activation': ['logistic', 'tanh', 'relu'],\n",
    "    'alpha': [1e-4, 1e-3, 1e-2, 1e-1],\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'max_iter': randint(500, 2000),  # Random integer values between 100 and 1000\n",
    "}\n",
    "\n",
    "# Define the RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    mlp, param_distributions=param_dist, n_iter=10, cv=5, random_state=42\n",
    ")\n",
    "\n",
    "# Perform the random search\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Display the best hyperparameters\n",
    "print(\"Best Hyperparameters:\")\n",
    "print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:\n",
      "{'activation': 'relu', 'alpha': 0.01, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'max_iter': 1832}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Hyperparameters:\")\n",
    "print(random_search.best_params_)\n",
    "best_mlp = random_search.best_estimator_\n",
    "y_pred_mlp = best_mlp.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      1.00         1\n",
      "           1       0.20      0.33      0.25         6\n",
      "           2       0.00      0.00      1.00         5\n",
      "           3       0.41      0.50      0.45        14\n",
      "           4       0.00      0.00      1.00         1\n",
      "           5       0.00      0.00      1.00         3\n",
      "           6       0.14      0.50      0.22         4\n",
      "           7       0.00      0.00      1.00         1\n",
      "           8       0.00      1.00      0.00         0\n",
      "           9       0.25      0.25      0.25        16\n",
      "          10       0.00      0.00      1.00         2\n",
      "          11       0.00      0.00      1.00         1\n",
      "\n",
      "   micro avg       0.17      0.28      0.21        54\n",
      "   macro avg       0.08      0.22      0.68        54\n",
      "weighted avg       0.21      0.28      0.49        54\n",
      " samples avg       0.18      0.54      0.57        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred_mlp, y_test, zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performances of the model are definitively better than the Random Forest, but still worse than the Bert based model from `class_infection_source.ipynb`. It looks like the extra info coming with the whole text are useful for a better prediction. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
